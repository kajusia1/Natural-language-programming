{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b945437",
   "metadata": {},
   "source": [
    "<h3> Podsumowanie i uzupłenienie wiadomości o Napisach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eaf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"To jest przykladowy tekst.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcbbab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] #zerowy znak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c1db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o j'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:4] #znaki: 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2e25cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ex\" in x #czy fragment \"ex\" jest w napisie x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39d8fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"and\" not in x #czy prawdą jest, ze \"and\" nie znajduje sie w napisie x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6876a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1] #ostatni znak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd91f1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st przykladowy tekst.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5:] #znaki od 5 do konca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4205710b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ekst.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-5:] #ostatnie 5 znakow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4176ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To', 'jest', 'przykladowy', 'tekst.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\" \") #podziel tekst ze wzgledu na spacje i zapisz poszczegolne slowa do listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b9adbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', ' jest przyklad', 'wy tekst.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split(\"o\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bced23dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.startswith(\"Th\") #czy tekst zapisany w zmiennej x zaczyna sie od Th?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029a9955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.endswith(\".\") #czy tekst zapisany w zmiennej x konczy sie kropką?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f9e2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count(\"e\") #policz liczbe wystapien litery \"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507d683b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To jXst przykladowy tXkst.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.replace(\"e\",\"X\") #zamien wszystkie wystapienia \"e\" na \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f588997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TO JEST PRZYKLADOWY TEKST.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.upper()  #zamien wszystkie znaki na duze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7581476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to jest przykladowy tekst.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.lower()  #zamien wszystkie znaki na male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152a6add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tO JEST PRZYKLADOWY TEKST.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.swapcase() #te co byly duze niech beda male, a male duze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5054f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([\"py\",\"t\",\"hon\"]) #zlacz liste slow w jedno slowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8479b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'py_t_hon'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_\".join([\"py\",\"t\",\"hon\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4905ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cbff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation #znaki interpunkcyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3765ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.digits #cyfry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c2bb3",
   "metadata": {},
   "source": [
    "<h3> NLTK - biblioteka do przetwarzania języka naturalnego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5d3be",
   "metadata": {},
   "source": [
    "<h4> Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f92bb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e290884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'. Most cells are only visible under a microscope. Cells emerged on Earth about 4 billion years ago. All cells are capable of replication, protein synthesis, and motility. Cells are broadly categorized into two types: eukaryotic cells, which possess a nucleus, and prokaryotic cells, which lack a nucleus but have a nucleoid region. Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be either single-celled, such as amoebae, or multicellular, such as some algae, plants, animals, and fungi. Eukaryotic cells contain organelles including mitochondria, which provide energy for cell functions; chloroplasts, which create sugars by photosynthesis, in plants; and ribosomes, which synthesise proteins.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0edc0c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kajaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kajaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kajaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "544d2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The cell is the basic structural and functional unit of all forms of life.', 'Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function.', \"The term comes from the Latin word cellula meaning 'small room'.\", 'Most cells are only visible under a microscope.', 'Cells emerged on Earth about 4 billion years ago.', 'All cells are capable of replication, protein synthesis, and motility.', 'Cells are broadly categorized into two types: eukaryotic cells, which possess a nucleus, and prokaryotic cells, which lack a nucleus but have a nucleoid region.', 'Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be either single-celled, such as amoebae, or multicellular, such as some algae, plants, animals, and fungi.', 'Eukaryotic cells contain organelles including mitochondria, which provide energy for cell functions; chloroplasts, which create sugars by photosynthesis, in plants; and ribosomes, which synthesise proteins.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(ex_text)) #podzial na sentencje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a4bab",
   "metadata": {},
   "source": [
    "<h4> Zadanie1: Porównaj zastosowanie metody split z kropką oraz metody sent_tokenize na tekście: \"Mr. Smith is a scientist. He is also a very good teacher.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "066e3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cell', 'is', 'the', 'basic', 'structural', 'and', 'functional', 'unit', 'of', 'all', 'forms', 'of', 'life', '.', 'Every', 'cell', 'consists', 'of', 'cytoplasm', 'enclosed', 'within', 'a', 'membrane', ';', 'many', 'cells', 'contain', 'organelles', ',', 'each', 'with', 'a', 'specific', 'function', '.', 'The', 'term', 'comes', 'from', 'the', 'Latin', 'word', 'cellula', 'meaning', \"'small\", 'room', \"'\", '.', 'Most', 'cells', 'are', 'only', 'visible', 'under', 'a', 'microscope', '.', 'Cells', 'emerged', 'on', 'Earth', 'about', '4', 'billion', 'years', 'ago', '.', 'All', 'cells', 'are', 'capable', 'of', 'replication', ',', 'protein', 'synthesis', ',', 'and', 'motility', '.', 'Cells', 'are', 'broadly', 'categorized', 'into', 'two', 'types', ':', 'eukaryotic', 'cells', ',', 'which', 'possess', 'a', 'nucleus', ',', 'and', 'prokaryotic', 'cells', ',', 'which', 'lack', 'a', 'nucleus', 'but', 'have', 'a', 'nucleoid', 'region', '.', 'Prokaryotes', 'are', 'single-celled', 'organisms', 'such', 'as', 'bacteria', ',', 'whereas', 'eukaryotes', 'can', 'be', 'either', 'single-celled', ',', 'such', 'as', 'amoebae', ',', 'or', 'multicellular', ',', 'such', 'as', 'some', 'algae', ',', 'plants', ',', 'animals', ',', 'and', 'fungi', '.', 'Eukaryotic', 'cells', 'contain', 'organelles', 'including', 'mitochondria', ',', 'which', 'provide', 'energy', 'for', 'cell', 'functions', ';', 'chloroplasts', ',', 'which', 'create', 'sugars', 'by', 'photosynthesis', ',', 'in', 'plants', ';', 'and', 'ribosomes', ',', 'which', 'synthesise', 'proteins', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(ex_text)) #podzial na slowa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b324825",
   "metadata": {},
   "source": [
    "<h4> Zadanie2: Zdefiniuj funkcję, która dla danego tekstu zwraca liste słów z małej litery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09fc9536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'cell',\n",
       " 'is',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'structural',\n",
       " 'and',\n",
       " 'functional',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'all',\n",
       " 'forms',\n",
       " 'of',\n",
       " 'life',\n",
       " '.',\n",
       " 'every',\n",
       " 'cell',\n",
       " 'consists',\n",
       " 'of',\n",
       " 'cytoplasm',\n",
       " 'enclosed',\n",
       " 'within',\n",
       " 'a',\n",
       " 'membrane',\n",
       " ';',\n",
       " 'many',\n",
       " 'cells',\n",
       " 'contain',\n",
       " 'organelles',\n",
       " ',',\n",
       " 'each',\n",
       " 'with',\n",
       " 'a',\n",
       " 'specific',\n",
       " 'function',\n",
       " '.',\n",
       " 'the',\n",
       " 'term',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'the',\n",
       " 'latin',\n",
       " 'word',\n",
       " 'cellula',\n",
       " 'meaning',\n",
       " \"'small\",\n",
       " 'room',\n",
       " \"'\",\n",
       " '.',\n",
       " 'most',\n",
       " 'cells',\n",
       " 'are',\n",
       " 'only',\n",
       " 'visible',\n",
       " 'under',\n",
       " 'a',\n",
       " 'microscope',\n",
       " '.',\n",
       " 'cells',\n",
       " 'emerged',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'about',\n",
       " '4',\n",
       " 'billion',\n",
       " 'years',\n",
       " 'ago',\n",
       " '.',\n",
       " 'all',\n",
       " 'cells',\n",
       " 'are',\n",
       " 'capable',\n",
       " 'of',\n",
       " 'replication',\n",
       " ',',\n",
       " 'protein',\n",
       " 'synthesis',\n",
       " ',',\n",
       " 'and',\n",
       " 'motility',\n",
       " '.',\n",
       " 'cells',\n",
       " 'are',\n",
       " 'broadly',\n",
       " 'categorized',\n",
       " 'into',\n",
       " 'two',\n",
       " 'types',\n",
       " ':',\n",
       " 'eukaryotic',\n",
       " 'cells',\n",
       " ',',\n",
       " 'which',\n",
       " 'possess',\n",
       " 'a',\n",
       " 'nucleus',\n",
       " ',',\n",
       " 'and',\n",
       " 'prokaryotic',\n",
       " 'cells',\n",
       " ',',\n",
       " 'which',\n",
       " 'lack',\n",
       " 'a',\n",
       " 'nucleus',\n",
       " 'but',\n",
       " 'have',\n",
       " 'a',\n",
       " 'nucleoid',\n",
       " 'region',\n",
       " '.',\n",
       " 'prokaryotes',\n",
       " 'are',\n",
       " 'single-celled',\n",
       " 'organisms',\n",
       " 'such',\n",
       " 'as',\n",
       " 'bacteria',\n",
       " ',',\n",
       " 'whereas',\n",
       " 'eukaryotes',\n",
       " 'can',\n",
       " 'be',\n",
       " 'either',\n",
       " 'single-celled',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'amoebae',\n",
       " ',',\n",
       " 'or',\n",
       " 'multicellular',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'some',\n",
       " 'algae',\n",
       " ',',\n",
       " 'plants',\n",
       " ',',\n",
       " 'animals',\n",
       " ',',\n",
       " 'and',\n",
       " 'fungi',\n",
       " '.',\n",
       " 'eukaryotic',\n",
       " 'cells',\n",
       " 'contain',\n",
       " 'organelles',\n",
       " 'including',\n",
       " 'mitochondria',\n",
       " ',',\n",
       " 'which',\n",
       " 'provide',\n",
       " 'energy',\n",
       " 'for',\n",
       " 'cell',\n",
       " 'functions',\n",
       " ';',\n",
       " 'chloroplasts',\n",
       " ',',\n",
       " 'which',\n",
       " 'create',\n",
       " 'sugars',\n",
       " 'by',\n",
       " 'photosynthesis',\n",
       " ',',\n",
       " 'in',\n",
       " 'plants',\n",
       " ';',\n",
       " 'and',\n",
       " 'ribosomes',\n",
       " ',',\n",
       " 'which',\n",
       " 'synthesise',\n",
       " 'proteins',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smallist(str):\n",
    "    str = str.lower()\n",
    "    str = word_tokenize(str)\n",
    "    return str\n",
    "\n",
    "smallist(ex_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff12483",
   "metadata": {},
   "source": [
    "<h4> Zadanie3: Załaduj plik tekstowy o nazwie \"example_text.txt\", a następnie zapisz pod zmienną  $txt\\_words$  liste słów (z małej litery) występujących w tekście. Dodatkowo: <br>\n",
    "    \n",
    "- Wyświetl pierwsze 20 słów.\n",
    "- Ile słów znajduje się w tekście?\n",
    "- Ile występuje słów unikatowych?\n",
    "- Wyznacz tzw. miarę Herdana  $C=\\frac{\\log V}{\\log M}$ , gdzie  V  - liczba różnych słów,  M  - liczba wszystkich słów.\n",
    "- Ile razy wystąpiło słowo $woman$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21b04bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwsze 20:  ['no', '.', '1111', '(', 'sanitary', ')', ',', 'dated', 'ootacamund', ',', 'the', '6th', 'october', '1876.', 'from-the', 'honourable', 'w.', 'hudleston', ',']\n",
      "M:  92927\n",
      "V:  8182\n",
      "Miara Herdana C:  0.7875901173182093\n",
      "Ilość wystąpień woman:  20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(\"example_text.txt\") as file:\n",
    "    example_text = file.read()\n",
    "\n",
    "txt_words = smallist(example_text)\n",
    "\n",
    "print(\"Pierwsze 20: \",txt_words[:19])\n",
    "\n",
    "M = len(txt_words)\n",
    "print(\"M: \",M)\n",
    "\n",
    "unique = set(txt_words)\n",
    "\n",
    "V = len(unique)\n",
    "print(\"V: \",V)\n",
    "\n",
    "import math \n",
    "\n",
    "C=  math.log(V)/math.log(M)\n",
    "print(\"Miara Herdana C: \", C)\n",
    "\n",
    "print(\"Ilość wystąpień woman: \",txt_words.count(\"woman\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400e4a9",
   "metadata": {},
   "source": [
    "Pobierz korpus https://data.nls.uk/data/digitised-collections/a-medical-history-of-british-india/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c11c4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', '.', '1111', '(', 'Sanitary', '),', 'dated', 'Ootacamund', ',', 'the']\n"
     ]
    }
   ],
   "source": [
    "#Tokenizacja korpusu\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader #do czytania kolekcji dokumentow\n",
    "\n",
    "\n",
    "corpus_root = 'nls-text-indiaPapers/' #nazwa katalogu w ktorym znajdują sie dokumenty tekstowe\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*', encoding='latin1') #pod zmienna wordlists zapisz wszystkie pliki wsytepujace w sciezce podanej powyzej\n",
    "corpus_tokens = wordlists.words()  #metoda do tokenizacji tego zbioru dokumentow i zapisaniu w postaci listy tokenów (słów)\n",
    "\n",
    "print(corpus_tokens[:10]) #wyswietl pierwsze 10 slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780c27a",
   "metadata": {},
   "source": [
    "<h4> Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8a31623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b18de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kajaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords.readme().replace('\\n', ' ') #opis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edbc1b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"she's\", 'needn', 'yourself', \"he'd\", 'should', 'them', 'didn', 'itself', 'the', 'me', 'are', \"we're\", 'in', 'has', \"shouldn't\", 'most', 'those', \"wouldn't\", 'now', \"i'd\", \"i'm\", \"wasn't\", 'had', 'i', 'for', 'themselves', 'there', 're', 'and', 'some', 'at', \"you'd\", 'she', \"haven't\", 'before', 'her', 'by', 'doesn', 'be', 'our', 'into', 'd', 'ain', 'having', \"don't\", 'mustn', 'until', 'over', 'other', 'was', 'shouldn', 'is', 'hadn', 'on', 'these', 'am', 'which', 'his', 'y', 'more', \"she'd\", 'up', \"you've\", 'a', 'both', 'if', \"they've\", \"that'll\", 'then', 'you', \"you're\", \"they'd\", \"isn't\", 'each', 'hers', 'from', 'below', 'who', 'again', 'all', 'any', 'or', \"doesn't\", 'own', 'whom', 'been', 'during', \"he'll\", \"it's\", \"shan't\", 'he', 'only', 'won', 've', \"they'll\", 'as', 'between', 'ma', 'than', \"we'd\", 'here', \"weren't\", 'have', 'theirs', 'hasn', 'very', 'couldn', 'out', 'above', 'do', 'm', \"needn't\", 'weren', \"i've\", 'my', 'isn', 'o', \"hasn't\", 'herself', 'mightn', 'while', 'about', 'were', 'where', 'through', 'wouldn', 'few', 'such', 'to', 'they', 'doing', 'ours', 'can', 'shan', 'too', 'being', 'haven', 's', 'further', 'it', 'myself', 'that', 'down', 'not', \"you'll\", 'because', 'with', \"it'd\", 'no', 'aren', 'just', 'against', 'how', 'what', 'yourselves', \"didn't\", 'under', \"we'll\", \"mightn't\", \"i'll\", \"she'll\", \"mustn't\", 'your', \"couldn't\", 'yours', 'same', 'don', 'why', 'does', 'its', 'll', \"should've\", \"we've\", 'after', 'their', 'of', \"won't\", 'an', 'once', 'nor', 'this', 't', 'him', 'did', \"hadn't\", 'wasn', \"it'll\", \"aren't\", 'off', \"he's\", 'will', 'himself', 'ourselves', 'when', \"they're\", 'but', 'so', 'we'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) #angielskie stopwords\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a320d06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.fileids()) #inne języki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88672459",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sentence = \"This is an example 1, showing off stop words filtration that occur using NLTK library.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f473f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', '1', ',', 'showing', 'off', 'stop', 'words', 'filtration', 'that', 'occur', 'using', 'NLTK', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(ex_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63bc7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', '1', ',', 'showing', 'stop', 'words', 'filtration', 'occur', 'using', 'NLTK', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "print([elem for elem in word_tokenize(ex_sentence) if elem not in stop_words ]) #bez stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7091494",
   "metadata": {},
   "source": [
    "<h4> Zadanie4: Zapisz do listy  $pure\\_words$  słowa występujące w napisie  $ex\\_sentence$  niebędące stop words, znakami interpunkcyjnymi czy cyframi (oczywiście w sposób automatyczny)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "095da9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'showing', 'stop', 'words', 'filtration', 'occur', 'using', 'NLTK', 'library']\n"
     ]
    }
   ],
   "source": [
    "pure_words = [elem for elem in word_tokenize(ex_sentence) if elem not in stop_words and elem not in string.punctuation and elem not in string.digits]\n",
    "print(pure_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300411d0",
   "metadata": {},
   "source": [
    "<h4> Zadanie5: Utwórz słownik zawierający jako klucze  stopwords  a wartościami niech będzie liczba ich występień (ze wszystkich dokumentów zawartych w 'nls-text-indiaPapers/'). Które z nich występowało najczęściej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecfd24fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'the', 'from', 'the', 'to', 'the', 'of', 'to', 'the', 'to']\n",
      "['no', 'the', 'from', 'to', 'of', 'i', 'am', 're', 'for', 'and']\n",
      "[76388, 1193271, 103147, 340151, 784526, 78835, 4891, 13122, 141043, 442524]\n",
      "Najczęściej występujące stopword: \"the\" - 1193271 razy\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# stopwords\n",
    "filtered_stopwords = [word.lower() for word in corpus_tokens if word.lower() in stop_words]\n",
    "print(filtered_stopwords[:10])\n",
    "\n",
    "# ilość stopwords, Counter zlicza występowanie elemetów i zapisuje je do słownika\n",
    "stopwords_freq = Counter(filtered_stopwords)\n",
    "print(list(stopwords_freq)[:10])\n",
    "print(list(stopwords_freq.values())[:10])\n",
    "\n",
    "# Wyświetlenie najczęściej występującego stopworda\n",
    "most_common_word, most_common_count = stopwords_freq.most_common(1)[0]\n",
    "print(f'Najczęściej występujące stopword: \"{most_common_word}\" - {most_common_count} razy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334700a",
   "metadata": {},
   "source": [
    "<h4> Klasyfikacja języka na podstawie stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68b14dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"La cellule est l'unité biologique structurelle et fonctionnelle fondamentale de tous les êtres vivants connus. C'est la plus petite unité vivante capable de se reproduire de façon autonome. La science qui étudie les cellules est appelée biologie cellulaire.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9339fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize #tokenizacja ze względu na interpunkcje i spacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94aaf973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La', 'cellule', 'est', 'l', \"'\", 'unité', 'biologique', 'structurelle', 'et', 'fonctionnelle', 'fondamentale', 'de', 'tous', 'les', 'êtres', 'vivants', 'connus', '.', 'C', \"'\", 'est', 'la', 'plus', 'petite', 'unité', 'vivante', 'capable', 'de', 'se', 'reproduire', 'de', 'façon', 'autonome', '.', 'La', 'science', 'qui', 'étudie', 'les', 'cellules', 'est', 'appelée', 'biologie', 'cellulaire', '.']\n"
     ]
    }
   ],
   "source": [
    "ex_tokens = wordpunct_tokenize(ex_text)\n",
    "\n",
    "print(ex_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "026bb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'albanian': 1, 'arabic': 0, 'azerbaijani': 1, 'basque': 0, 'belarusian': 0, 'bengali': 0, 'catalan': 5, 'chinese': 0, 'danish': 2, 'dutch': 1, 'english': 0, 'finnish': 2, 'french': 9, 'german': 0, 'greek': 0, 'hebrew': 0, 'hinglish': 3, 'hungarian': 1, 'indonesian': 1, 'italian': 4, 'kazakh': 0, 'nepali': 0, 'norwegian': 2, 'portuguese': 2, 'romanian': 3, 'russian': 0, 'slovene': 1, 'spanish': 4, 'swedish': 1, 'tajik': 0, 'turkish': 1}\n"
     ]
    }
   ],
   "source": [
    "language_ratios = {} #tworze pusty slownik\n",
    "\n",
    "ex_words = [word.lower() for word in ex_tokens] #zamieniam wszystkie litery na male \n",
    "unique_words_set = set(ex_words) #slowa unikatowe zapisuje w postaci zbioru\n",
    "\n",
    "for language in stopwords.fileids(): #dla kazdego jezyka \n",
    "    stopwords_set = set(stopwords.words(language)) #do stopwords_set zapisuje stopwords (danego jezyka) w formie zbioru\n",
    "    common_elements = unique_words_set.intersection(stopwords_set) #przeciecie zbiorow (A.intersection(B) to inaczej A∩B)\n",
    "    language_ratios[language] = len(common_elements) #zaliczam ile wspolnych elementow ma dany jezyk a wystepujace w tekscie stop words\n",
    "    \n",
    "\n",
    "print(language_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad2455bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french\n"
     ]
    }
   ],
   "source": [
    "most_rated_language = max(language_ratios, key=language_ratios.get) #zapisuje jezyk ktory ma najwiecej stop_words w tekscie\n",
    "print(most_rated_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba35397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'est', 'qui', 'se', 'la', 'et', 'de', 'les', 'l', 'c'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_words_set.intersection(set(stopwords.words(most_rated_language)))) #jakie są to słowa? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dcebb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'se'}\n"
     ]
    }
   ],
   "source": [
    "#ciekawe są stop_words słoweńskie wystepujace w tekscie \n",
    "\n",
    "print(unique_words_set.intersection(set(stopwords.words('slovene')))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a5c94",
   "metadata": {},
   "source": [
    "<h3> Zastosowanie wyrażeń regularnych w NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a446c96",
   "metadata": {},
   "source": [
    "- [abc] <-- a lub b lub c\n",
    "- [A-Z] <-- od A do Z\n",
    "- [^X] <-- wszystko z wyjątkiem X\n",
    "- . <-- cokolwiek\n",
    "- \\d <-- dowolna cyfra od 0 do 9\n",
    "- \\D <-- wszystko z wyjątkiem cyfr [^d]\n",
    "- \\s <-- spacja\n",
    "- \\S <-- wszystko co nie jest spacją\n",
    "- \\w <-- a-z, A-Z, cyfry, podkreślenie _\n",
    "- *<-- żadne lub dowolnej długości powtórzenie, np ca*t znaczy ct, cat, caat, caaat...\n",
    "- +<-- jedno lub więcej powtórzenie, np ca+t znaczy cat, caat, caaat...\n",
    "- ? <-- żadne wystąpienie lub jedno wystąpienie, np pyt?hon znaczy pyhon lub python\n",
    "- {n} <-- znaczy, że coś ma nastąpić n razy\n",
    "- {n,m} <-- znaczy, że coś ma nastąpić między n a m razy np ab{1,3}c znaczy abc, abbc, abbbc\n",
    "- (X|Y) <-- X lub Y\n",
    "- ^x <-- znaczy, że od x ma sie zacząć wyraz\n",
    "- x$ <-- znaczy, że na x ma sie kończyc wyraz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d5e68",
   "metadata": {},
   "source": [
    "<h4> Zadanie6: Podaj po dwa przykłady wyrazów (mające sens lub nie), które spełniają następujące wyrażenia regularne:\n",
    "    \n",
    "    \n",
    "    \n",
    "- '.ma.*': amassssssssssssssssssssssssssssssssssssssssssssss, imak\n",
    "- 'meal?': mea, meal\n",
    "- 'go{2,6}gle': gooooogle, google\n",
    "- 'a[knm]e': ane, ake\n",
    "- 'b[^a]d': bid, bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f580046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #biblioteka do wyrażeń regularnych w Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da49049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['women', 'women', 'women', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'women', 'woman', 'women', 'women', 'woman', 'women', 'woman', 'women', 'woman', 'woman', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women']\n"
     ]
    }
   ],
   "source": [
    "#Uwaga: txt_words trzeba sobie utworzyc w zadaniu 3\n",
    "\n",
    "womaen_strings=[w for w in txt_words if re.search('^wom[ae]n$', w)] #znajdź w liście wyrazów txt_words słowa spełniające podane wyrażenie regularne. Co ono oznacza?\n",
    "print(womaen_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1e785",
   "metadata": {},
   "source": [
    "<h4> Zadanie7: Wykonaj analogiczne przeszukiwanie z wzorcem 'wom[ae]n' i porównaj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d60e8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['women', 'women', 'women', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'woman', 'women', 'woman', 'women', 'women', 'woman', 'women', 'woman', 'women', 'washerwoman', 'woman', 'woman', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women', 'women', 'women', 'women', 'woman', 'woman', 'women', 'women', 'women']\n"
     ]
    }
   ],
   "source": [
    "womaen_strings=[w for w in txt_words if re.search('wom[ae]n', w)] #znajdź w liście wyrazów txt_words słowa spełniające podane wyrażenie regularne. Co ono oznacza?\n",
    "print(womaen_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d8910",
   "metadata": {},
   "source": [
    "<h4> Zadanie8: Wykonaj analogiczne przeszukiwanie, tym razem poszukując słów o łącznej liczbie znaków 13, które zaczynają się od 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b646eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antiscorbutic', 'approximately', 'approximately', 'agriculturist', 'ages.-chiefly', 'approximately', 'accommodation']\n"
     ]
    }
   ],
   "source": [
    "a13_strings=[w for w in txt_words if re.search('^a.{12}$', w)] #znajdź w liście wyrazów txt_words słowa spełniające podane wyrażenie regularne. Co ono oznacza?\n",
    "print(a13_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15c01c",
   "metadata": {},
   "source": [
    "<h4> Zadanie9: Wykonaj analogiczne przeszukiwanie, tym razem poszukując słów o łącznej liczbie znaków 13, które nie zaczynają się od małej litery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ae888b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24-pergunnahs', '19.-commenced', '24-pergunuahs', '24-pergunnahs', '24-pergunnahs', '1875.-patches']\n"
     ]
    }
   ],
   "source": [
    "small13_strings=[w for w in txt_words if re.search('^[^a-z].{12}$', w)] #znajdź w liście wyrazów txt_words słowa spełniające podane wyrażenie regularne. Co ono oznacza?\n",
    "print(small13_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954af0a4",
   "metadata": {},
   "source": [
    "<h4> Własna tokenizacja z użyciem wyrazeń regularnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aff15e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3339cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\") #tak definiuje slowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ce4417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The genome of Bacteroides vulgatus was found to contain DNA that belongs to a virus they called BV01. Next, they had to determine whether the virus could escape or reinfect the host. The researchers found that conditions in the gut may act to stimulate the activity of BV01.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2627b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'genome', 'of', 'Bacteroides', 'vulgatus', 'was', 'found', 'to', 'contain', 'DNA', 'that', 'belongs', 'to', 'a', 'virus', 'they', 'called', 'BV', 'Next', 'they', 'had', 'to', 'determine', 'whether', 'the', 'virus', 'could', 'escape', 'or', 'reinfect', 'the', 'host', 'The', 'researchers', 'found', 'that', 'conditions', 'in', 'the', 'gut', 'may', 'act', 'to', 'stimulate', 'the', 'activity', 'of', 'BV']\n"
     ]
    }
   ],
   "source": [
    "s_tokenized = tokenizer.tokenize(s)\n",
    "\n",
    "print(s_tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pbioinf1.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
