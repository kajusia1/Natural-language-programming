{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie1: Czy fakt, że nie oczyściliśmy danych ze stopwords czy znaków interpunkcyjncyh znacząco wpłynął na pogorszenie predykcji? Odpowiedź uzasadnij (bez obliczeń, chodzi o 2 zdania komentarza)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie wpływa istotnie na accuracy, prawdopodobnie przez to, że znaki interpunkcyjne i stopwords występują z podobną częstotliwością w obu zbiorach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie2: Powtórz 20 razy predykcję za pomocą metody Naive Bayes za każdym razem tasując listę documents (po co?). Zapisz do listy dokładności uzyskane za każdym razem. Wyznacz średnią dokładność i odchylenie standardowe z tych dokładności (wcześniej przerób listę na obiekt typu array). Narysuj histogram dokładności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78.0, 83.0, 78.0, 85.0, 82.0, 86.0, 79.0, 79.0, 81.0, 81.0, 74.0, 82.0, 80.0, 78.0, 74.0, 83.0, 84.0, 80.0, 77.0, 81.0]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews #korpus z recenzjami - 1000 poztytywnych i 1000 negatywnych\n",
    "\n",
    "#Tworze funkcje, ktorej argumentami będzie lista wyrazow, a ktora będzie wywolywana dla kolejnych recenzji, będe sprawdzal czy występują w niej slowa z word_features\n",
    "def find_features(document): #przez document rozumiemy tutaj lista wyrazow\n",
    "    words = set(document)    #patrze na unikatowe slowa\n",
    "    features = {}            #tworzę pusty slownik\n",
    "    for w in word_features: #word_features zdefiniowane wyzej [lista 3000 najczęstych slow we wszystkich recenzjach]\n",
    "        features[w] = (w in words) #True or False, dla kazdego slowa z word_features w zaleznosci czy jest czy nie w dokumencie\n",
    "    return features\n",
    "\n",
    "documents = [] \n",
    "\n",
    "for category in movie_reviews.categories(): #dla kazdej z kategorii (pos/neg)\n",
    "    for fileid in movie_reviews.fileids(category): #dla wszytkich recenzji z danej kategorii\n",
    "        documents.append((list(movie_reviews.words(fileid)), category)) #dodaj element typu ([slowa z recenzji], 'pos/neg')\n",
    "\n",
    "import random #losowe libczy\n",
    "\n",
    "classifiers = []\n",
    "for i in range(20):\n",
    "    random.shuffle(documents) #tasowanie kolejności\n",
    "\n",
    "    all_words = [] #tu będą wszystkie slowa występujące we wszystkich recenzjach\n",
    "    \n",
    "    for w in movie_reviews.words():  #dla wszystkich slow ze wszystkich dokumentow korpusu movie_reviews\n",
    "        all_words.append(w.lower())  #dodaje do listy all_words slowa zapisane z malej litery\n",
    "\n",
    "    all_words = nltk.FreqDist(all_words) #liczę częstosci slow i nadpisuje zmienną all_words\n",
    "    word_features = [x[0] for x in all_words.most_common(3000)] #do zmiennej word_features zapisuje pierwsze 3000 najczęstszych slow\n",
    "\n",
    "    featuresets = [(find_features(rev),category) for (rev,category) in documents] #zapisuje liste krotek (slownik jak wyzej, pos/neg)\n",
    "\n",
    "    training_set = featuresets[:1900] #jako zbior treningowy biorę pierwsze 1900 recenzji\n",
    "    testing_set = featuresets[1900:]  #jako zbior tetowy biorę pozostałe recenzje\n",
    "    #wykonuje algorytm Naive Bayes na zbiorze treningowym\n",
    "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "    classifiers.append((nltk.classify.accuracy(classifier,testing_set))*100)\n",
    "\n",
    "print(classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.25\n",
      "3.1603006186120965\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classifiers = np.array(classifiers)\n",
    "print(classifiers.mean())\n",
    "print(classifiers.std())\n",
    "plt.hist(classifiers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie3: Wyjaśnij czemu istotnym jest aby grupy tekstów reprezentujących klasy były w miarę równoliczne. Zbuduj model NaiveBayes, gdzie jako zbiór treningowy wybierz 900 recenzji pozytywnych i 100 negatywnych. Następnie zabadaj jak model sprawdza się na 100 pozostałych recenzjach pozytywnych a jak na 100 negatywnych (innych niż przy trenowaniu modelu). Skomentuj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy nierównolicznych zbiorach danych dla klas, model będzie gorzej przewidywał katoegorie dla mniej licznego zbioru. Raz, że ma mniejszą baze do nauki, dwa -  prawdopodobieństwo bardziej licznej kategorii będzie większe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for positive: 99.0\n",
      "Accuracy for negative: 28.999999999999996\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews \n",
    "movie_reviews.categories()\n",
    "\n",
    "documents = [] \n",
    "\n",
    "for category in movie_reviews.categories(): \n",
    "    for fileid in movie_reviews.fileids(category): \n",
    "        documents.append((list(movie_reviews.words(fileid)), category)) \n",
    "\n",
    "import random \n",
    "    \n",
    "all_words = [] \n",
    "\n",
    "for w in movie_reviews.words():  \n",
    "    all_words.append(w.lower())  \n",
    "\n",
    "all_words = nltk.FreqDist(all_words) \n",
    "word_features = [x[0] for x in all_words.most_common(3000)] \n",
    "\n",
    "def find_features(document): #przez document rozumiemy tutaj lista wyrazow\n",
    "    words = set(document)    #patrze na unikatowe slowa\n",
    "    features = {}            #tworzę pusty slownik\n",
    "    for w in word_features: #word_features zdefiniowane wyzej [lista 3000 najczęstych slow we wszystkich recenzjach]\n",
    "        features[w] = (w in words) #True or False, dla kazdego slowa z word_features w zaleznosci czy jest czy nie w dokumencie\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev),category) for (rev,category) in documents] \n",
    "\n",
    "training_set = featuresets[:100] + featuresets[1000:1900]  \n",
    "testing_set_neg = featuresets[100:200]\n",
    "testing_set_pos = featuresets[1900:]  \n",
    "\n",
    "#Naive Bayes na zbiorze treningowym\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "accuracy_pos = nltk.classify.accuracy(classifier,testing_set_pos)*100\n",
    "accuracy_neg = nltk.classify.accuracy(classifier,testing_set_neg)*100\n",
    "\n",
    "print(f\"Accuracy for positive: {accuracy_pos}\\nAccuracy for negative: {accuracy_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie4: Zbuduj model do predykcji wiadomości SPAM/HAM. W tym celu użyj pliku  spam_ham.txt . Każda wiadomość opatrzona jest odpowiednim tagiem na początku kolejnego wiersza. Sprawdź ile w pliku znajduje się wiadomości typu SPAM i HAM. Uwzględnij uwagę z poprzedniego zadania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam needed:  4079\n",
      "Ham:  4826\n",
      "Spam:  4826\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "with open(\"spam_ham.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "#obróbka danych\n",
    "data =[]\n",
    "for i in range(0, len(lines)-1):\n",
    "    tag = lines[i].split(\"\\t\")[0].strip()\n",
    "    message = lines[i].split(\"\\t\")[1].strip()\n",
    "    data.append((tag, message))\n",
    "\n",
    "#function that generates new spam messages, len(newspam) = len(spam), use as many times as you want\n",
    "def generate_spam(data):\n",
    "    part1_list =[]\n",
    "    part2_list =[]\n",
    "    part3_list =[]\n",
    "    part4_list =[]\n",
    "\n",
    "    spam = [message for tag, message in data if tag == \"spam\"]\n",
    "\n",
    "    # przy podziale na dwa accuracy była mniejsza\n",
    "    for message in spam:\n",
    "        message = message.split()\n",
    "        a = len(message)//4\n",
    "        part1_list.append(' '.join(message[:a]))\n",
    "        part2_list.append(' '.join(message[a:2*a]))\n",
    "        part3_list.append(' '.join(message[2*a:3*a]))\n",
    "        part4_list.append(' '.join(message[3*a:]))\n",
    "        \n",
    "    import random\n",
    "    random.shuffle(part1_list)\n",
    "    random.shuffle(part2_list)\n",
    "    random.shuffle(part3_list)\n",
    "    random.shuffle(part4_list)\n",
    "\n",
    "    new_spam = []\n",
    "    for i in range(len(part1_list)):\n",
    "        new_spam.append(part1_list[i] + \" \" + part2_list[i] + \" \" + part3_list[i] + \" \" + part4_list[i])\n",
    "    return new_spam\n",
    "\n",
    "#how much spam do we need\n",
    "print(\"Spam needed: \", len([tag for tag, message in data if tag == \"ham\"]) - len([tag for tag, message in data if tag == \"spam\"]))\n",
    "new_spam = []\n",
    "for i in range(((len([tag for tag, message in data if tag == \"ham\"]) - len([tag for tag, message in data if tag == \"spam\"]))// len([tag for tag, message in data if tag == \"spam\"])) +1):\n",
    "    new_spam = new_spam + generate_spam(data)\n",
    "new_spam = new_spam[:4079]\n",
    "\n",
    "#otagowanie spamu\n",
    "new_spam_tagged= []\n",
    "for spam in new_spam:\n",
    "    new_spam_tagged.append((\"spam\", spam))\n",
    "\n",
    "data = data + new_spam_tagged\n",
    "\n",
    "# tasowanie\n",
    "random.shuffle(data)\n",
    "\n",
    "#ostatni check czy na pewno jest po równo\n",
    "print(\"Ham: \", len( [message for tag, message in data if tag == \"ham\"]))\n",
    "print(\"Spam: \", len( [message for tag, message in data if tag == \"spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.30543572044866%\n",
      "Most Informative Features\n",
      "                       £ = True             spam : ham    =    314.3 : 1.0\n",
      "                   Nokia = True             spam : ham    =    104.4 : 1.0\n",
      "                    1000 = True             spam : ham    =     93.3 : 1.0\n",
      "                    draw = True             spam : ham    =     87.5 : 1.0\n",
      "                 service = True             spam : ham    =     82.5 : 1.0\n",
      "                  Mobile = True             spam : ham    =     68.6 : 1.0\n",
      "                   await = True             spam : ham    =     60.8 : 1.0\n",
      "                 voucher = True             spam : ham    =     58.2 : 1.0\n",
      "                  camera = True             spam : ham    =     56.9 : 1.0\n",
      "                  select = True             spam : ham    =     55.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def prep_text(text):\n",
    "    doc = nlp(text) #change text to spacy \n",
    "    #lemmatisation, omits words with numbers (is_alpha) and stopwords (is.stop)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "# data prep for naivebayes\n",
    "def get_features(text):\n",
    "    return {word: True for word in prep_text(text)}\n",
    "\n",
    "#model creation\n",
    "featuresets = [(get_features(message), label) for (label, message) in data]\n",
    "train_set = featuresets[:5016]  #train set (more less 90%)\n",
    "test_set = featuresets[5016:]  # test set\n",
    "\n",
    "#model training\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "#testing\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2286    1]\n",
      " [ 263 2086]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for features, actual_label in test_set:\n",
    "    predicted_label = classifier.classify(features)\n",
    "    true_labels.append(actual_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=['spam', 'ham'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można zastosować też np. https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto przejrzeć: https://poleval.pl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie5: Przeanalizuj dane allegro-reviews za pomocą modelu NaiveBayes. \n",
    "    \n",
    "- Zbuduj model w którym rozważysz tylko recenzje z ocenami 5. i 1.\n",
    "- Zbuduj model dla pełnych danych.\n",
    "- Dokonaj modyfikacji, które poprawią te modele.\n",
    "\n",
    "Uwagi:\n",
    "- dane są już podzielone na zbiór treningowy i testowy\n",
    "- dane nie są zbilasnowane, warto coś z tym zrobić\n",
    "- warto ograniczyć liczbę słów, może jakaś lemmatyzacja?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/PL-MTEB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL DLA 5 i 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"PL-MTEB/allegro-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spam(data_to_generate_from):\n",
    "    part1_list =[]\n",
    "    part2_list =[]\n",
    "    part3_list =[]\n",
    "    part4_list =[]\n",
    "\n",
    "    # przy podziale na dwa accuracy była mniejsza\n",
    "    # split the message into 4 parts\n",
    "    for message in data_to_generate_from:\n",
    "        message = message.split()\n",
    "        a = len(message)//4\n",
    "        part1_list.append(' '.join(message[:a]))\n",
    "        part2_list.append(' '.join(message[a:2*a]))\n",
    "        part3_list.append(' '.join(message[2*a:3*a]))\n",
    "        part4_list.append(' '.join(message[3*a:]))\n",
    "        \n",
    "    # shuffle parts lists    \n",
    "    import random\n",
    "    random.shuffle(part1_list)\n",
    "    random.shuffle(part2_list)\n",
    "    random.shuffle(part3_list)\n",
    "    random.shuffle(part4_list)\n",
    "\n",
    "    # connect parts and generate the new data set\n",
    "    new_data = []\n",
    "    for i in range(len(part1_list)):\n",
    "        new_data.append(part1_list[i] + \" \" + part2_list[i] + \" \" + part3_list[i] + \" \" + part4_list[i])\n",
    "    return new_data\n",
    "\n",
    "#get list name\n",
    "def get_list_name(lst):\n",
    "    # find the list name\n",
    "    for name, value in globals().items():\n",
    "        if value is lst:\n",
    "            return name\n",
    "    return None \n",
    "\n",
    "def augment_data(data_set_to_augment, tag_to_aug, tag_full, data_to_generate_from):\n",
    "    \n",
    "    new_data = []\n",
    "    #create a list of new messages\n",
    "    for i in range(((len([tag for text, tag in data_set_to_augment if tag == tag_full]) - len([tag for text, tag in data_set_to_augment if tag == tag_to_aug]))// len([tag for text, tag in data_set_to_augment if tag == tag_to_aug])) +1):\n",
    "        new_data = new_data + generate_spam(data_to_generate_from)\n",
    "    new_data = new_data[:len([text for text, tag in data_set_to_augment if tag == tag_full]) - len([text for text, tag in data_set_to_augment if tag == tag_to_aug])]\n",
    "    print(f\"Data for {get_list_name(data_set_to_augment)} generated...\")\n",
    "    \n",
    "    #tag messages\n",
    "    new_data_tagged= []\n",
    "    for text in new_data:\n",
    "        new_data_tagged.append((text, tag_to_aug))\n",
    "    print(\"Data tagged...\")\n",
    "\n",
    "    #add new data to original data\n",
    "    data_set_to_augment = data_set_to_augment + new_data_tagged\n",
    "\n",
    "    print(\"Final check:\")\n",
    "    print(f\"{tag_to_aug} augmented: \", len([text for text, tag in data_set_to_augment if tag == tag_to_aug]))\n",
    "    print(f\"{tag_full}: {len([text for text, tag in data_set_to_augment if tag == tag_full])} \\n\")\n",
    "    return data_set_to_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for train_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "1.0 augmented:  4259\n",
      "5.0: 4259 \n",
      "\n",
      "Data for test_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "1.0 augmented:  372\n",
      "5.0: 372 \n",
      "\n",
      "Accuracy: 88.44086021505376%\n",
      "Most Informative Features\n",
      "                   błoto = True              1.0 : 5.0    =     64.6 : 1.0\n",
      "               tragiczny = True              1.0 : 5.0    =     53.0 : 1.0\n",
      "                odradzać = True              1.0 : 5.0    =     48.3 : 1.0\n",
      "              wyrzucenie = True              1.0 : 5.0    =     46.3 : 1.0\n",
      "               niezgodny = True              1.0 : 5.0    =     40.3 : 1.0\n",
      "                 fatalny = True              1.0 : 5.0    =     40.2 : 1.0\n",
      "            wyrzucić być = True              1.0 : 5.0    =     37.7 : 1.0\n",
      "                   szajs = True              1.0 : 5.0    =     34.3 : 1.0\n",
      "                wyrzucyć = True              1.0 : 5.0    =     30.6 : 1.0\n",
      "                Tragedia = True              1.0 : 5.0    =     29.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from datasets import load_dataset\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "import random\n",
    "\n",
    "#filter reviews\n",
    "def filter_reviews(dataset_split):\n",
    "    return [(entry['text'], entry['label']) for entry in dataset_split if entry['label'] in [1, 5]]\n",
    "\n",
    "train_data = filter_reviews(dataset['train'])\n",
    "val_data = filter_reviews(dataset['validation'])\n",
    "test_data = filter_reviews(dataset['test'])\n",
    "\n",
    "#join train set and val set\n",
    "train_data.extend(val_data)\n",
    "\n",
    "#augment data\n",
    "train_data = augment_data(train_data, 1.0, 5.0, [text for text, tag in train_data if tag == 1])\n",
    "test_data = augment_data(test_data, 1.0, 5.0, [text for text, tag in test_data if tag == 1])\n",
    "\n",
    "# spacy\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "def prep_text(text):\n",
    "    doc = nlp(text) #change text to spacy \n",
    "    #lemmatisation, omits words with numbers (is_alpha) and stopwords (is.stop)\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "# data prep for naivebayes\n",
    "def get_features(text):\n",
    "    return {word: True for word in prep_text(text)}\n",
    "\n",
    "train_set = [(get_features(text), label) for text, label in train_data]\n",
    "test_set = [(get_features(text), label) for text, label in test_data]\n",
    "\n",
    "# model training\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# check model accuracy\n",
    "print(f'Accuracy: {accuracy(classifier, test_set) * 100}%')\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL DLA WSZYSTKICH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for train_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "1 augmented:  4259\n",
      "5: 4259 \n",
      "\n",
      "Data for test_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "1 augmented:  372\n",
      "5: 372 \n",
      "\n",
      "Data for train_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "2 augmented:  4259\n",
      "5: 4259 \n",
      "\n",
      "Data for test_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "2 augmented:  372\n",
      "5: 372 \n",
      "\n",
      "Data for train_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "3 augmented:  4259\n",
      "5: 4259 \n",
      "\n",
      "Data for test_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "3 augmented:  372\n",
      "5: 372 \n",
      "\n",
      "Data for train_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "4 augmented:  4259\n",
      "5: 4259 \n",
      "\n",
      "Data for test_data generated...\n",
      "Data tagged...\n",
      "Final check:\n",
      "4 augmented:  372\n",
      "5: 372 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"PL-MTEB/allegro-reviews\")\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "import random\n",
    "\n",
    "#filter reviews\n",
    "def filter_reviews(dataset_split):\n",
    "    return [(entry['text'], entry['label']) for entry in dataset_split if entry['label'] in [1, 2, 3, 4, 5]]\n",
    "\n",
    "train_data = filter_reviews(dataset['train'])\n",
    "val_data = filter_reviews(dataset['validation'])\n",
    "test_data = filter_reviews(dataset['test'])\n",
    "\n",
    "#join train set and val set\n",
    "train_data.extend(val_data)\n",
    "\n",
    "#augment data (the most 5 reviews)\n",
    "for i in range(1,5):\n",
    "    train_data = augment_data(train_data, i, 5, [text for text, tag in train_data if tag == i])\n",
    "    test_data = augment_data(test_data, i, 5, [text for text, tag in test_data if tag == i])\n",
    "\n",
    "# spacy\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "def prep_text(text):\n",
    "    doc = nlp(text) #change text to spacy \n",
    "    #lemmatisation, omits words with numbers (is_alpha) and stopwords (is.stop)\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "# data prep for naivebayes\n",
    "def get_features(text):\n",
    "    return {word: True for word in prep_text(text)}\n",
    "\n",
    "train_set = [(get_features(text), label) for text, label in train_data]\n",
    "test_set = [(get_features(text), label) for text, label in test_data]\n",
    "\n",
    "# model training\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.03225806451613%\n",
      "Most Informative Features\n",
      "                   błoto = True              1.0 : 5.0    =     67.4 : 1.0\n",
      "               tragiczny = True              1.0 : 5.0    =     50.3 : 1.0\n",
      "                odradzać = True              1.0 : 5.0    =     49.5 : 1.0\n",
      "                 wyrzucć = True              1.0 : 2.0    =     47.7 : 1.0\n",
      "              wyrzucenie = True              1.0 : 5.0    =     44.3 : 1.0\n",
      "                 fatalny = True              1.0 : 5.0    =     40.2 : 1.0\n",
      "               niezgodny = True              1.0 : 5.0    =     39.7 : 1.0\n",
      "            wyrzucić być = True              1.0 : 5.0    =     37.7 : 1.0\n",
      "                   szajs = True              1.0 : 5.0    =     36.3 : 1.0\n",
      "                Tragedia = True              1.0 : 5.0    =     31.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# check model accuracy\n",
    "print(f'Accuracy: {accuracy(classifier, test_set) * 100}%')\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[223  65  60  22   2]\n",
      " [ 87  63 124  96   2]\n",
      " [ 34  70 129 124  15]\n",
      " [ 17  29 107 208  11]\n",
      " [ 17  25  50 177 103]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for features, actual_label in test_set:\n",
    "    predicted_label = classifier.classify(features)\n",
    "    true_labels.append(actual_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=[1,2,3,4,5])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please find modified models above (lemmatisation, data augmentation, detetion of stopwords and words including letters). Accuracy is much higher for 1/5 reviews because the data is more divergent. It can be seen in the confusion matrix of 1-5 reviews as the model struggled with identifying reviews that were closly related e.g. 4 and 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pbioinf1.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
